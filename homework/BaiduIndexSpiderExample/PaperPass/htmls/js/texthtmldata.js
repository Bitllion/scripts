var detailJsonData = [{"content":"基于 Python的疫情与心理健康的百度指数数据挖掘与可视化分析","sectionCount":1,"score":0.0},{"content":"摘要：","sectionCount":2,"score":0.0},{"content":"随着新冠继续影响世界，有数据表明，疫情不仅带来经济上的灾难，也带来了人类心理健康上的灾难，","sectionCount":2,"score":0.0},{"content":"越来越多的人，因为疫情防控，被封在家，或者感染后被他人歧视等原因，带来了不小的心理疾病，","sectionCount":2,"score":0.0},{"content":"比如抑郁症，抑郁症的发病数量明显随着疫情的扩大而增高，通过python在百度指数上的爬虫对数据挖掘和利用python图形库制作可视化的图，","sectionCount":2,"score":0.0},{"content":"可以很清晰地了解到疫情和抑郁症的关系，也将帮助政府和国家对民众心理进行及时的指导和干预。","sectionCount":2,"score":0.0},{"content":"Data mining and visual analysis of Baidu Index on epidemic situation and mental health based on Python","sectionCount":3,"score":0.0},{"content":"Abstract:","sectionCount":4,"score":0.0},{"content":":","sectionCount":4,"score":0.0},{"content":"As the new crown continues to affect the world, some data show that the epidemic has not only brought about economic disasters,","sectionCount":4,"score":0.0},{"content":"but also brought about disasters in human mental health.","sectionCount":4,"score":0.5543478},{"content":"More and more people have brought about many psychological diseases, such as depression, because of epidemic prevention and control,","sectionCount":4,"score":0.0},{"content":"being closed at home, or being discriminated against by others after infection.","sectionCount":4,"score":0.5401786},{"content":"The incidence of depression has obviously increased with the expansion of the epidemic, We can clearly understand the relationship between epidemic","sectionCount":4,"score":0.0},{"content":"and depression through data mining by Python crawlers on Baidu Index and making visual graphs by using Python graphics library.","sectionCount":4,"score":0.0},{"content":"0 引言","sectionCount":5,"score":0.0},{"content":"随着互联网技术的高速发展，大数据时代的来临，数据规模极具膨胀，但数据存在着难以高效率地获取和分析的挑战。","sectionCount":6,"score":0.50776917},{"content":"数据科学，俨然成了关乎科技进步的核心基础设施。","sectionCount":6,"score":0.0},{"content":"在国外，著名的搜索引擎谷歌利用大数据分析并预测人们在搜索框内的输入，","sectionCount":6,"score":0.0},{"content":"在国内，像购物app淘宝、娱乐app抖音，都广泛地利用大数据建立每个用户的个人画像，","sectionCount":6,"score":0.0},{"content":"推送更被人们喜欢的广告或短视频。数据科学的发展，给人们的生活带来了极大的便利；","sectionCount":6,"score":0.51751095},{"content":"数据科学，已经得到了人民的认可，也得到了政府和党的大力支持，习近平总书记强调，","sectionCount":6,"score":0.0},{"content":"国家要大力实施大数据战略，发展数字经济和数字中国的建设。","sectionCount":6,"score":0.51453686},{"content":"目前，介于新冠疫情的严峻形式，疫情防控依然是我国的首要工作之一，","sectionCount":7,"score":0.0},{"content":"根据全球著名医学杂志《柳叶刀》的最新报告（Global prevalence and burden of depressive and","sectionCount":7,"score":0.0},{"content":"anxiety disorders in 204 countries and territories in 2020 due to the COVID-19 pandemic）显示，","sectionCount":7,"score":0.51886564},{"content":"疫情带给人们不仅是经济上的损失，更多的是身心健康上的损害。","sectionCount":7,"score":0.0},{"content":"在政府给予民众必要的生活物资的同时，还需要更多地关心民众在身心健康上的问题，并给予及时和有效的治疗。","sectionCount":7,"score":0.0},{"content":"如何获取疫情与身心健康的相关信息？","sectionCount":7,"score":0.0},{"content":"每日的新冠阳性数量的增加是否和抑郁症数量的增加呈正相关？","sectionCount":7,"score":0.0},{"content":"急需心理治疗的人数是否因为疫情有所增加？","sectionCount":7,"score":0.0},{"content":"网络爬虫是一种高效地从互联网获取数据的技术手段，依据几个特定的关键词，","sectionCount":8,"score":0.41952708},{"content":"可以爬取指定日期、指定地区，甚至特定的性格人群的计算机程序。","sectionCount":8,"score":0.0},{"content":"利用网络爬虫，依据不同的需求，制定相应的程序规则，自动地爬取想要的信息，并将数据持久化地保存在计算机上。","sectionCount":8,"score":0.0},{"content":"本文以百度指数为爬取平台，制定的关键词有“新增阳性”、“抑郁症”、“地区“、”抑郁症治疗“、”疫情“等，","sectionCount":9,"score":0.0},{"content":"基于python 语言设计的一套网络爬虫程序，完成对目标关键词百度指数信息的获取，存储数据后，","sectionCount":9,"score":0.0},{"content":"再通过python的数据库和绘图库对数据做量化分析和模型的建立，并以可视化的形式更直观地展现出来。","sectionCount":9,"score":0.0},{"content":"综上所述，我们可以利用爬虫技术获取疫情与心理健康的数据，","sectionCount":10,"score":0.5317461},{"content":"并利用数据分析技术建立一套相关性的模型，","sectionCount":10,"score":0.5436508},{"content":"给出强用的证据展示疫情和心理疾病的强关联性，","sectionCount":10,"score":0.0},{"content":"帮助政府预测和治疗因为疫情导致的心理疾病的人群。","sectionCount":10,"score":0.0},{"content":"价值","sectionCount":11,"score":0.0},{"content":"      （一）本课题的学术价值","sectionCount":11,"score":0.0},{"content":"目前学术界很少人利用百度指数做数据的分析和预测，本课题可以通过数据爬取、分析，建立一套通用的大数据预测模型。","sectionCount":12,"score":0.0},{"content":"目前学术界很少有人研究疫情与心理疾病的关系，并给出良好的应对措施，本课题可以分析出疫情与心理疾病变化的关系。","sectionCount":13,"score":0.0},{"content":"（二）本课题的应用价值","sectionCount":14,"score":0.0},{"content":"基于百度指数爬取各种的数据信息，建立疫情风险预测模型。","sectionCount":15,"score":0.44037357},{"content":"基于百度指数的爬取的数据信息，建立疫情与心理疾病的防范机制。","sectionCount":16,"score":0.0},{"content":"2课题研究对象","sectionCount":17,"score":0.0},{"content":"本课题的研究对象是疫情与心理健康的关系。","sectionCount":18,"score":0.5384615},{"content":"随着疫情的扩大，心理健康出现问题的人数是否相应的增多，以及需要接受心理治疗的人数的变化关系。","sectionCount":18,"score":0.0},{"content":"3 主要内容","sectionCount":19,"score":0.0},{"content":"      3.1 python 介绍","sectionCount":19,"score":0.0},{"content":"Python 是一种具有动态语义的解释型、面向对象的高级编程语言。它的高级内置数据结构，结合动态类型和动态绑定，使其对快速应用程序开发非常有吸引力，也可以用作脚本或胶水语言将现有组件连接在一起。Python 简单易学的语法强调可读性，因此降低了程序维护的成本。Python 支持模块和包，这鼓励程序模块化和代码重用。","sectionCount":20,"score":0.8687029},{"content":"3.2 爬虫介绍","sectionCount":21,"score":0.0},{"content":"      3.2.1 爬虫原理","sectionCount":21,"score":0.0},{"content":"网络爬虫：网络爬虫（也称为网络蜘蛛，网络机器人），它是一个经验法则，自动从万维网上抓取信息的程序或脚本。","sectionCount":22,"score":0.6776729},{"content":"一个请求网站并提取数据的自动化程序，可以理解为蜘蛛在互联网上爬行，","sectionCount":22,"score":0.53968257},{"content":"互联网可以比作一张大网，爬虫在这个大网上爬行，遇到一些有趣的网站资源，","sectionCount":22,"score":0.584127},{"content":"可以模拟一个浏览器并抓取它，然后将其放入 CSV 数据库等。","sectionCount":22,"score":0.0},{"content":"3.2.2 爬虫分类","sectionCount":23,"score":0.0},{"content":"根据实现的技术和结构，网络爬虫可以分为一般网络爬虫、聚焦网络爬虫、增量网络爬虫和深度网络爬虫。","sectionCount":24,"score":0.76622015},{"content":"3.3.3 爬虫的基本工作流程","sectionCount":25,"score":0.0},{"content":"（1）获取初始 URL。","sectionCount":26,"score":0.0},{"content":"初始URL是网络爬虫的入口点，链接到需要爬取的网页。","sectionCount":26,"score":0.41302976},{"content":"（2）在抓取网页时，我们需要获取页面的 HTML 内容，然后对其进行解析以获取链接到该页面的所有页面的 URL。","sectionCount":27,"score":0.0},{"content":"（3）将这些 URL 放入队列中。","sectionCount":28,"score":0.0},{"content":"（4）循环遍历队列，从队列中逐一读取URL，对于每个URL，爬取对应的网页，然后重复上面的爬取过程。","sectionCount":29,"score":0.0},{"content":"（5）检查是否满足停止条件。如果没有设置停止条件，爬虫会一直爬到无法获取到新的URL。","sectionCount":30,"score":0.63703704},{"content":"3.3 数据挖掘","sectionCount":31,"score":0.0},{"content":"      3.3.1获取COOKIE","sectionCount":31,"score":0.0},{"content":"百度指数需要登录才能爬取，它使用COOKIE进行身份验证，所以需要先获取COOKIE ，打开Chrome浏览器, 访问百度指数的首页并登录，","sectionCount":32,"score":0.0},{"content":"按F12 调出开发者模式，点击状态栏的“网络“，并勾选保留日志的功能，选中 ”Fetch/XHR”，","sectionCount":32,"score":0.0},{"content":"再次刷新网页，找到其中的GET请求，其中某些请求包含COOKIE参数，点击复制COOKIE的 value","sectionCount":32,"score":0.0},{"content":"3.3.2.导入第三方相关库","sectionCount":33,"score":0.0},{"content":"      import time, random, json, pandas as pd","sectionCount":33,"score":0.0},{"content":"      from qdata.baidu_index import get_search_index","sectionCount":33,"score":0.0},{"content":"      from qdata.baidu_index.common import split_keywords","sectionCount":33,"score":0.0},{"content":"      3.3.3准备cookie和关键词","sectionCount":33,"score":0.0},{"content":"      keywords_list \u003d [[\"抑郁症\"], [\"疫情\"]]","sectionCount":33,"score":0.0},{"content":"      cookies \u003d \"\"\"\"\"\"","sectionCount":33,"score":0.0},{"content":"      3.3.4核心代码如下","sectionCount":33,"score":0.0},{"content":"def spider(keywords_list, start_date, end_date, cookies):","sectionCount":34,"score":0.62690634},{"content":"print(\"爬虫开始工作\")","sectionCount":35,"score":0.0},{"content":"      all_list \u003d []","sectionCount":35,"score":0.0},{"content":"      # 计时","sectionCount":35,"score":0.0},{"content":"      tic \u003d time.time()","sectionCount":35,"score":0.0},{"content":"      # 遍历关键词","sectionCount":35,"score":0.0},{"content":"      for keywords in split_keywords(keywords_list):","sectionCount":35,"score":0.0},{"content":"      for index in get_search_index(","sectionCount":35,"score":0.0},{"content":"      keywords_list\u003dkeywords,","sectionCount":35,"score":0.0},{"content":"      start_date\u003dstart_date,","sectionCount":35,"score":0.0},{"content":"      end_date\u003dend_date,","sectionCount":35,"score":0.0},{"content":"      cookies\u003dcookies,","sectionCount":35,"score":0.0},{"content":"      ):","sectionCount":35,"score":0.0},{"content":"      if index[\"type\"] \u003d\u003d \"all\":","sectionCount":35,"score":0.0},{"content":"      s \u003d {","sectionCount":35,"score":0.0},{"content":"      \"keyword\":","sectionCount":35,"score":0.0},{"content":"index[\"keyword\"][0],","sectionCount":35,"score":0.0},{"content":"      \"date\":","sectionCount":35,"score":0.0},{"content":"index[\"date\"],","sectionCount":35,"score":0.0},{"content":"      \"index_num\":","sectionCount":35,"score":0.0},{"content":"int(index[\"index\"]),","sectionCount":35,"score":0.0},{"content":"      }","sectionCount":35,"score":0.0},{"content":"      all_list.append(s)","sectionCount":35,"score":0.0},{"content":"      print(\"正在爬取：","sectionCount":35,"score":0.0},{"content":"%s\" % index)","sectionCount":35,"score":0.0},{"content":"      # 随机睡眠，防止被屏蔽","sectionCount":35,"score":0.0},{"content":"      time.sleep(random.uniform(3, 5))","sectionCount":35,"score":0.0},{"content":"      toc \u003d time.time()","sectionCount":35,"score":0.0},{"content":"      shijian \u003d toc - tic","sectionCount":35,"score":0.0},{"content":"      print(\"耗时%.2f秒,爬取完成！","sectionCount":35,"score":0.0},{"content":"\\n开始写入json\" % shijian)","sectionCount":35,"score":0.0},{"content":"      3.3.5 将数据写入json文件中","sectionCount":35,"score":0.0},{"content":"      with open(\"temp.json\", \"w\") as f:","sectionCount":35,"score":0.0},{"content":"      f.write(json.dumps(all_list))","sectionCount":35,"score":0.0},{"content":"      print(\"写入完成\")","sectionCount":35,"score":0.0},{"content":"      3.3.6 将数据写入excle文件中","sectionCount":35,"score":0.0},{"content":"      print(\"json转csv\")","sectionCount":35,"score":0.0},{"content":"      # 写入csv","sectionCount":35,"score":0.0},{"content":"      df \u003d pd.read_json(\".\\\\data\\\\temp.json\")","sectionCount":35,"score":0.0},{"content":"      df.to_csv(\".\\\\data\\\\temp.csv\", index\u003dNone)","sectionCount":35,"score":0.0},{"content":"      print(\"转csv完成！","sectionCount":35,"score":0.0},{"content":"\")","sectionCount":35,"score":0.0},{"content":"      3.4 数据处理","sectionCount":35,"score":0.0},{"content":"爬取好的数据已经按照日期依次保存keyword、date 、index的key和value在json数组的文件中, 由于我们的时间范围跨度过大，","sectionCount":36,"score":0.0},{"content":"从疫情开始到现在，所以我们需要将数据合并处理，以月份为单位","sectionCount":36,"score":0.0},{"content":"合并的代码如下:","sectionCount":37,"score":0.0},{"content":"      def analyse(keywords_length):","sectionCount":37,"score":0.0},{"content":"      print(\"开始分析数据\")","sectionCount":37,"score":0.0},{"content":"      df \u003d pd.read_csv(\".\\\\data\\\\temp.csv\")","sectionCount":37,"score":0.0},{"content":"# keyword分组 合算 每天到每月 的 index_num 数值 ，并重新将分组后的数据放入新的dataframe中","sectionCount":38,"score":0.0},{"content":"df[\"date\"] \u003d pd.to_datetime(df[\"date\"])","sectionCount":39,"score":0.0},{"content":"df \u003d df.set_index(\"date\").groupby(\"keyword\").resample(\"m\").sum().reset_index()","sectionCount":40,"score":0.0},{"content":"# 保存","sectionCount":41,"score":0.0},{"content":"      df.to_csv(\".\\\\data\\sum.csv\")","sectionCount":41,"score":0.0},{"content":"      # 转化为list","sectionCount":41,"score":0.0},{"content":"list_df \u003d pd.read_csv(\".\\\\data\\\\sum.csv\")","sectionCount":42,"score":0.582981},{"content":"index_list_df \u003d list_df.groupby(\"keyword\")[\"index_num\"].apply(list)","sectionCount":43,"score":0.0},{"content":"# 保存为json","sectionCount":44,"score":0.0},{"content":"      index_list \u003d []","sectionCount":44,"score":0.0},{"content":"      for i in range(keywords_length):","sectionCount":44,"score":0.0},{"content":"      index_json \u003d {","sectionCount":44,"score":0.0},{"content":"      \"keyword\":","sectionCount":44,"score":0.0},{"content":"index_list_df.index[i],","sectionCount":44,"score":0.0},{"content":"      \"index_sum\":","sectionCount":44,"score":0.0},{"content":"index_list_df.values[i],","sectionCount":44,"score":0.0},{"content":"      }","sectionCount":44,"score":0.0},{"content":"      index_list.append(index_json)","sectionCount":44,"score":0.0},{"content":"      with open(\".\\\\data\\\\index_list.json\", \"w\") as f:","sectionCount":44,"score":0.0},{"content":"      f.write(json.dumps(index_list))","sectionCount":44,"score":0.0},{"content":"      print(\"分析完成！","sectionCount":44,"score":0.0},{"content":"\")","sectionCount":44,"score":0.0},{"content":"      os.remove(\".\\\\data\\\\temp.csv\")","sectionCount":44,"score":0.0},{"content":"      os.remove(\".\\\\data\\\\temp.json\")","sectionCount":44,"score":0.0},{"content":"      3.4 数据可视化","sectionCount":44,"score":0.0},{"content":"数据可视化是将信息转换为视觉环境（如地图或图形）的实践，以使数据更易于人脑理解和获取见解。数据可视化的主要目标是更容易识别大型数据集中的模式、趋势和异常值。","sectionCount":45,"score":0.7920079},{"content":"可视化之前，我们首先需要引入必须的第三方库：","sectionCount":46,"score":0.0},{"content":"import matplotlib.pyplot as plt","sectionCount":47,"score":0.0},{"content":"      import sys, json, pandas as pd","sectionCount":47,"score":0.0},{"content":"      import numpy as np","sectionCount":47,"score":0.0},{"content":"      sys.path.append(\".\")","sectionCount":47,"score":0.0},{"content":"然后将百度指数数据放入一个数组中：","sectionCount":48,"score":0.5921568},{"content":"def get_index_list(keyword):","sectionCount":49,"score":0.0},{"content":"      with open(\".\\\\data\\\\index_list.json\", \"r\") as f:","sectionCount":49,"score":0.0},{"content":"      date_list_json \u003d json.load(f)","sectionCount":49,"score":0.0},{"content":"      for i in range(len(keyword)):","sectionCount":49,"score":0.0},{"content":"      if date_list_json[i][\"keyword\"] \u003d\u003d keyword:","sectionCount":49,"score":0.0},{"content":"      return date_list_json[i][\"index_sum\"]","sectionCount":49,"score":0.0},{"content":"      3.4.1 折线图","sectionCount":49,"score":0.0},{"content":"折线图是在直线上绘制数据点的一种方法。","sectionCount":50,"score":0.0},{"content":"通常，它用于显示趋势数据，或两个数据集的比较。","sectionCount":50,"score":0.0},{"content":"实现折线图的代码如下：","sectionCount":51,"score":0.0},{"content":"      def draw_mulite_line(list):","sectionCount":51,"score":0.0},{"content":"      print(\"开始绘制折线多图\")","sectionCount":51,"score":0.0},{"content":"      date_list \u003d get_date_list()","sectionCount":51,"score":0.0},{"content":"      x \u003d 1","sectionCount":51,"score":0.0},{"content":"      for i in list:","sectionCount":51,"score":0.0},{"content":"      plt.rcParams[\u0027font.sans-serif\u0027]\u003d[\u0027Microsoft YaHei\u0027]","sectionCount":51,"score":0.0},{"content":"      plt.xlabel(\"时间\")","sectionCount":51,"score":0.0},{"content":"      plt.ylabel(\"指数\")","sectionCount":51,"score":0.0},{"content":"      plt.subplot(1,2,x)","sectionCount":51,"score":0.0},{"content":"      x\u003dx+1","sectionCount":51,"score":0.0},{"content":"      plt.xticks(rotation\u003d30)","sectionCount":51,"score":0.0},{"content":"      plt.plot(date_list, get_index_list(i))","sectionCount":51,"score":0.0},{"content":"      plt.grid()","sectionCount":51,"score":0.0},{"content":"      plt.title(\"%s\"%i)","sectionCount":51,"score":0.0},{"content":"      plt.suptitle(\"折线图\")","sectionCount":51,"score":0.0},{"content":"      plt.savefig(\u0027.\\\\data\\\\mulite_line.png\u0027)","sectionCount":51,"score":0.0},{"content":"      plt.close()","sectionCount":51,"score":0.0},{"content":"      print(\"绘制完毕!","sectionCount":51,"score":0.0},{"content":"\")","sectionCount":51,"score":0.0},{"content":"很明显地看出，抑郁症的发病率和疫情热度呈正相关","sectionCount":52,"score":0.41642514},{"content":"3.4.2 柱状图","sectionCount":53,"score":0.0},{"content":"直方图是将一组数据点组织到用户指定范围的图形表示。柱状图在外观上类似于条形图，它通过获取许多数据点并将它们分组到逻辑范围或数据箱中，将数据序列压缩为易于解释的视觉效果。","sectionCount":54,"score":0.9880952},{"content":"实现代码如下：","sectionCount":55,"score":0.0},{"content":"      def draw_mulite_bar(list):","sectionCount":55,"score":0.0},{"content":"      print(\"开始绘制柱状多图\")","sectionCount":55,"score":0.0},{"content":"      x\u003d1","sectionCount":55,"score":0.0},{"content":"      for i in list:","sectionCount":55,"score":0.0},{"content":"      plt.rcParams[\u0027font.sans-serif\u0027]\u003d[\u0027Microsoft YaHei\u0027]","sectionCount":55,"score":0.0},{"content":"      plt.xlabel(\"时间\")","sectionCount":55,"score":0.0},{"content":"      plt.ylabel(\"指数\")","sectionCount":55,"score":0.0},{"content":"      plt.subplot(1,2,x)","sectionCount":55,"score":0.0},{"content":"      x\u003dx+1","sectionCount":55,"score":0.0},{"content":"      plt.xticks(rotation\u003d30)","sectionCount":55,"score":0.0},{"content":"      plt.bar(get_date_list(), get_index_list(i))","sectionCount":55,"score":0.0},{"content":"      plt.title(\"%s\"%i)","sectionCount":55,"score":0.0},{"content":"      plt.suptitle(\"柱状图图\")","sectionCount":55,"score":0.0},{"content":"      plt.savefig(\u0027.\\\\data\\\\mulite_bar.png\u0027)","sectionCount":55,"score":0.0},{"content":"      plt.close()","sectionCount":55,"score":0.0},{"content":"      print(\"绘制完毕\")","sectionCount":55,"score":0.0},{"content":"      效果如下:","sectionCount":55,"score":0.0},{"content":"在这张图中，抑郁症相对变化不是很明显，是由于其本身的庞大基数造成的","sectionCount":56,"score":0.0},{"content":"3.4.3 词云","sectionCount":57,"score":0.0},{"content":"词云（也称为文本云或标签云）的工作方式很简单：","sectionCount":58,"score":0.0},{"content":"特定词在文本数据源（如演讲、博客文章或数据库）中出现的次数越多，它在词云。","sectionCount":58,"score":0.0},{"content":"词云是用不同大小描绘的词的集合或集群。","sectionCount":58,"score":0.0},{"content":"单词出现的越大越粗，它在给定文本中被提及的次数越多，它就越重要。","sectionCount":58,"score":0.5130952},{"content":"也称为标签云或文本云，这些是提取文本数据最相关部分（从博客文章到数据库）的理想方法。","sectionCount":58,"score":0.0},{"content":"它们还可以帮助业务用户比较和对比两段不同的文本，以找出两者之间的措辞相似之处。","sectionCount":58,"score":0.0},{"content":"代码实现如下：","sectionCount":59,"score":0.0},{"content":"      import wordcloud, os, jieba","sectionCount":59,"score":0.0},{"content":"      import numpy as np","sectionCount":59,"score":0.0},{"content":"      from PIL import Image","sectionCount":59,"score":0.0},{"content":"      pwd \u003d os.getcwd()","sectionCount":59,"score":0.0},{"content":"      pic \u003d Image.open(r\"C:","sectionCount":59,"score":0.0},{"content":"\\Users\\fanyq\\Desktop\\baidu\\code\\libs\\pikaqiu.jpg\")","sectionCount":59,"score":0.0},{"content":"      shape \u003d np.array(pic)","sectionCount":59,"score":0.0},{"content":"      wc \u003d wordcloud.WordCloud(","sectionCount":59,"score":0.0},{"content":"mask\u003dshape, font_path\u003d\"simkai.ttf\", background_color\u003d\"white\", max_font_size\u003d100","sectionCount":60,"score":0.9},{"content":")","sectionCount":61,"score":0.0},{"content":"text \u003d open(pwd + \"\\\\data\\\\ci.txt\", \"r\", encoding\u003d\"UTF-8\").read()","sectionCount":62,"score":0.58556545},{"content":"cut_text \u003d jieba.cut(text)","sectionCount":63,"score":0.0},{"content":"      result \u003d \" \".join(cut_text)","sectionCount":63,"score":0.0},{"content":"      wc.generate(result)","sectionCount":63,"score":0.0},{"content":"      wc.to_file(pwd + \"\\\\data\\\\cloud.jpg\")","sectionCount":63,"score":0.0},{"content":"      效果如图：","sectionCount":63,"score":0.0},{"content":"      3.4.4 饼图","sectionCount":63,"score":0.0},{"content":"饼图（或圆图）是一种圆形统计图形，它被划分为多个部分以说明数字比例。","sectionCount":64,"score":0.0},{"content":"在饼图中，每个切片的弧长（以及相应的中心角和面积）与其表示的数量成比例。","sectionCount":64,"score":0.8133903},{"content":"虽然它的名字是因为它像一个被切成薄片的馅饼，但它的呈现方式也有不同。","sectionCount":64,"score":0.0},{"content":"实现代码如下：","sectionCount":65,"score":0.0},{"content":"      def draw_mulite_pie(list):","sectionCount":65,"score":0.0},{"content":"      print(\"开始绘制饼多图\")","sectionCount":65,"score":0.0},{"content":"      x\u003d1","sectionCount":65,"score":0.0},{"content":"      for i in list:","sectionCount":65,"score":0.0},{"content":"      plt.rcParams[\u0027font.sans-serif\u0027]\u003d[\u0027Microsoft YaHei\u0027]","sectionCount":65,"score":0.0},{"content":"      plt.subplot(1,2,x)","sectionCount":65,"score":0.0},{"content":"      x\u003dx+1","sectionCount":65,"score":0.0},{"content":"      plt.xticks(rotation\u003d30)","sectionCount":65,"score":0.0},{"content":"plt.pie( get_index_list(i),labels\u003dget_date_list(),autopct\u003d\u0027%.2f%%\u0027)","sectionCount":66,"score":0.0},{"content":"plt.title(\"%s\"%i)","sectionCount":67,"score":0.0},{"content":"      plt.suptitle(\"饼图\")","sectionCount":67,"score":0.0},{"content":"      plt.savefig(\u0027.\\\\data\\\\mulite_pie.png\u0027)","sectionCount":67,"score":0.0},{"content":"      plt.close()","sectionCount":67,"score":0.0},{"content":"      print(\"绘制完毕\")","sectionCount":67,"score":0.0},{"content":"      效果如下：","sectionCount":67,"score":0.0},{"content":"从这张图中，我们能看出每个月百度指数的百分比，由于疫情集中于三月份开始，","sectionCount":68,"score":0.0},{"content":"所以三月份热度占比最大，同理，抑郁症的热度也稍微有所增加。","sectionCount":68,"score":0.0},{"content":"3.4.5 散点图","sectionCount":69,"score":0.0},{"content":"散点图是一组数据的图形表示，其中变量对的值绘制在坐标系上。","sectionCount":70,"score":0.0},{"content":"该工具广泛应用于统计学和其他科学与工程领域，用于表示数据关系。","sectionCount":70,"score":0.41199777},{"content":"实现代码如下：","sectionCount":71,"score":0.0},{"content":"      def draw_mulite_matrix(list):","sectionCount":71,"score":0.0},{"content":"      print(\"开始绘制散点多图\")","sectionCount":71,"score":0.0},{"content":"      x\u003d1","sectionCount":71,"score":0.0},{"content":"      for i in list:","sectionCount":71,"score":0.0},{"content":"      plt.rcParams[\u0027font.sans-serif\u0027]\u003d[\u0027Microsoft YaHei\u0027]","sectionCount":71,"score":0.0},{"content":"      plt.xlabel(\"时间\")","sectionCount":71,"score":0.0},{"content":"      plt.ylabel(\"指数\")","sectionCount":71,"score":0.0},{"content":"      plt.subplot(1,2,x)","sectionCount":71,"score":0.0},{"content":"      x\u003dx+1","sectionCount":71,"score":0.0},{"content":"      plt.xticks(rotation\u003d30)","sectionCount":71,"score":0.0},{"content":"      plt.scatter(get_date_list(), get_index_list(i))","sectionCount":71,"score":0.0},{"content":"      plt.grid()","sectionCount":71,"score":0.0},{"content":"      plt.colorbar()","sectionCount":71,"score":0.0},{"content":"      plt.title(\"%s\"%i)","sectionCount":71,"score":0.0},{"content":"      plt.suptitle(\"矩阵点图\")","sectionCount":71,"score":0.0},{"content":"      plt.savefig(\u0027.\\\\data\\\\mulite_scatter.png\u0027)","sectionCount":71,"score":0.0},{"content":"      plt.close()","sectionCount":71,"score":0.0},{"content":"      print(\"绘制完毕\")","sectionCount":71,"score":0.0},{"content":"      效果如下：","sectionCount":71,"score":0.0},{"content":"‘散点图能详细的说明百度指数的具体数值，更具体的表现了疫情和抑郁症的关系","sectionCount":72,"score":0.0},{"content":"3.5 结果分析","sectionCount":73,"score":0.0},{"content":"本文通过爬取疫情和抑郁症的百度指数，获得2020一月份到2022五月份的 CSV 文件，","sectionCount":74,"score":0.0},{"content":"并用 Pandas 模块进行数据处理，matpoltlib模块绘制两者的饼图、柱状图、散点图、折线图。","sectionCount":74,"score":0.0},{"content":"然后将有效的数据进行提取，绘制词云。","sectionCount":74,"score":0.0},{"content":"再将疫情和抑郁症的百度指数进行统计，最后以Png文件的形式对天气数据可视化。","sectionCount":74,"score":0.0},{"content":"进一步可通过该案例分析每月的百度指数的变化关系，得出疫情和抑郁症的百度指数呈正相关，","sectionCount":74,"score":0.0},{"content":"政府有必要根据此，做出提前的预备方案，诱导民众的心理向好的方面发展。","sectionCount":74,"score":0.0},{"content":"4 总体框架","sectionCount":75,"score":0.0},{"content":"      5 思路方法","sectionCount":75,"score":0.0},{"content":"      抽样法：","sectionCount":75,"score":0.0},{"content":"在此基础上，从集合中选出一些具有代表性的单位，通过对这些选定单位的研究得出结论。","sectionCount":76,"score":0.0},{"content":"在日常生活中，我们在为家庭购买小麦、大米等物品时，不会对包装中的每一块小麦或大米进行检查，","sectionCount":76,"score":0.0},{"content":"而是对一些小麦或大米进行抽样，并以此为依据决定购买小麦或大米。","sectionCount":76,"score":0.0},{"content":". 通过这种方法可以节省时间和金钱。","sectionCount":76,"score":0.0},{"content":"在这种方法中保持极端谨慎是很重要的，否则可能会出现得出错误结论的可能性。","sectionCount":76,"score":0.0},{"content":"样本或范式政策基于三个被称为抽样原则的原则。","sectionCount":76,"score":0.0},{"content":"三大原理是概率原理、统计规律性原理和大数惯性原理。","sectionCount":76,"score":0.5625},{"content":"在此文中，我们将天数合并到月数，并随机抽选一部分作为调查","sectionCount":77,"score":0.0},{"content":"归因法","sectionCount":78,"score":0.0},{"content":"归因模型是一个规则或一组规则，用于确定如何将销售和转化功劳分配给转化路径中的接触点。","sectionCount":79,"score":0.8186813},{"content":"通过分析各种可视化的图形，将增长和下降的部分分别与因子相连接，可以分析出疫情与抑郁症存在正相关性。","sectionCount":79,"score":0.0},{"content":"例如，Analytics 中的Last Interaction模型将 100% 的功劳分配给紧接在销售或转化之前的最终接触点（即点击）。","sectionCount":79,"score":0.0},{"content":"相比之下，首次交互模型将 100% 的功劳分配给启动转化路径的接触点。","sectionCount":79,"score":0.6171717},{"content":"调查法","sectionCount":80,"score":0.0},{"content":"调查方法是一种过程、工具或技术，您可以通过向预定义的人群提问来收集研究中的信息。","sectionCount":81,"score":0.0},{"content":"通常，它有助于研究参与者与进行研究的个人或组织之间的信息交流。","sectionCount":81,"score":0.0},{"content":"6 创新之处","sectionCount":82,"score":0.0},{"content":"      学术思想特色和创新","sectionCount":82,"score":0.0},{"content":"本研究通过百度指数将疫情和抑郁症的变化关系通过可视化的方式展现出来，强有力地说明了抑郁症受疫情影响变化大，","sectionCount":83,"score":0.0},{"content":"减少疫情的恐慌、做好民众的心理疏通和治疗，也是后疫情时代必要的行政措施，对国家发展、民众身心健康起到促进作用。","sectionCount":83,"score":0.0},{"content":"学术观点特色和创新","sectionCount":84,"score":0.0},{"content":"本研究提出了将百度指数作为数据支撑的方法，百度指数来源于大数据的统计，具有一定的客观性、真实性、普遍性，","sectionCount":85,"score":0.0},{"content":"从另一个维度反映了社会舆论、心理的变化，开通了一条探索数据支撑、数据挖掘、数据分析、数据可视化的新道路。","sectionCount":85,"score":0.0},{"content":"学术方法特色和创新","sectionCount":86,"score":0.0},{"content":"研究视角和内容创新，本研究以百度指数为切入点，对疫情和抑郁症进行理论研究和实证方法，体现了新的视角。","sectionCount":87,"score":0.0},{"content":"研究方法创新，利用python爬虫对数据进行挖掘，再利用pandas进行矩阵分析，最后通过matplotlib绘制可视化的图形，","sectionCount":88,"score":0.0},{"content":"一套完整的数据挖掘和分析的流程充分说明了两者的联系。","sectionCount":88,"score":0.0},{"content":"7 参考文献","sectionCount":89,"score":0.0},{"content":"      【1】 娄岩主编.","sectionCount":89,"score":0.0},{"content":"PYTHON程序设计基础\u003dPYTHON PROGRAMMING BASICS.","sectionCount":89,"score":0.0},{"content":"北京：","sectionCount":89,"score":0.0},{"content":"机械工业出版社, 2021.01.","sectionCount":89,"score":0.0},{"content":"      【2】刘金花作. 文本挖掘与Python实践. 成都：","sectionCount":89,"score":0.0},{"content":"四川大学出版社, 2021.08.","sectionCount":89,"score":0.0},{"content":"      【3】郭洪伟编. 数据分析方法与应用. 北京：","sectionCount":89,"score":0.0},{"content":"首都经济贸易大学出版社, 2021.03.","sectionCount":89,"score":0.0},{"content":"      【4】宋万清，杨寿渊，陈剑雪，高永彬编著. 数据挖掘. 北京：","sectionCount":89,"score":0.0},{"content":"中国铁道出版社, 2019.01.","sectionCount":89,"score":0.0},{"content":"      【5】（美）大卫·洛辛（DavidLoshin）著；","sectionCount":89,"score":0.0},{"content":"尚慧萍，鲍忠贵译. 大数据分析. 北京：","sectionCount":89,"score":0.0},{"content":"国防工业出版社, 2020.01.","sectionCount":89,"score":0.0},{"content":"      【6】（日）松本健太郎著，田中景译. 大数据. 杭州：","sectionCount":89,"score":0.0},{"content":"浙江人民出版社, 2020.06.","sectionCount":89,"score":0.0},{"content":"      【7】李伊. 数据可视化. 北京：","sectionCount":89,"score":0.0},{"content":"首都经济贸易大学出版社, 2020.03.","sectionCount":89,"score":0.0},{"content":"      【8】 赵涵原.基于 Python 爬虫的书籍数据可视化分析[J].电 子技术与软件工程，2021（14）：","sectionCount":89,"score":0.0},{"content":"178-179.","sectionCount":89,"score":0.0},{"content":"      【9】吕云翔编著. 数据结构. 北京：","sectionCount":89,"score":0.0},{"content":"机械工业出版社, 2020.07.","sectionCount":89,"score":0.0},{"content":"      【10】A Survey:","sectionCount":89,"score":0.0},{"content":"How Python Pitches in IT-World","sectionCount":89,"score":0.0},{"content":"      【11】Hongnian Wang.IEEE .","sectionCount":89,"score":0.0},{"content":"Learning Deep Features for Giant Panda Gender Classification using Face Images","sectionCount":89,"score":0.0}];
var separateDetailJsonData = {"20":["推送更被人们喜欢的广告或短视频。","数据科学的发展，给人们的生活带来了极大的便利；"],"53":["Python 是一种具有动态语义的解释型、面向对象的高级编程语言。","它的高级内置数据结构，结合动态类型和动态绑定，使其对快速应用程序开发非常有吸引力，也可以用作脚本或胶水语言将现有组件连接在一起。","Python 简单易学的语法强调可读性，因此降低了程序维护的成本。","Python 支持模块和包，这鼓励程序模块化和代码重用。"],"56":["网络爬虫：","网络爬虫（也称为网络蜘蛛，网络机器人），它是一个经验法则，自动从万维网上抓取信息的程序或脚本。"],"68":["（5）检查是否满足停止条件。","如果没有设置停止条件，爬虫会一直爬到无法获取到新的URL。"],"156":["数据可视化是将信息转换为视觉环境（如地图或图形）的实践，以使数据更易于人脑理解和获取见解。","数据可视化的主要目标是更容易识别大型数据集中的模式、趋势和异常值。"],"194":["直方图是将一组数据点组织到用户指定范围的图形表示。","柱状图在外观上类似于条形图，它通过获取许多数据点并将它们分组到逻辑范围或数据箱中，将数据序列压缩为易于解释的视觉效果。"]};